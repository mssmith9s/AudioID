import numpy as np
import librosa
import os
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# Parameters
SAMPLE_RATE = 22050
DURATION = 2.5
N_MFCC = 40
NUM_CLASSES = 10

# Feature Extraction Function
def extract_features(file_path, sample_rate=SAMPLE_RATE, n_mfcc=N_MFCC):
    y, sr = librosa.load(file_path, sr=sample_rate, duration=DURATION)
    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)
    delta_mfccs = librosa.feature.delta(mfccs)
    delta_delta_mfccs = librosa.feature.delta(delta_mfccs)
    combined_features = np.stack([mfccs, delta_mfccs, delta_delta_mfccs], axis=-1)  # Combine as 3D tensor
    return combined_features

# Data Augmentation Function
def augment_audio(audio_data):
    augmented_data = []
    for feature in audio_data:
        stretched = librosa.effects.time_stretch(feature, rate=0.8)
        augmented_data.append(stretched)
        shifted = librosa.effects.pitch_shift(feature, sr=SAMPLE_RATE, n_steps=2)
        augmented_data.append(shifted)
        noise = np.random.randn(len(feature))
        noised = feature + 0.005 * noise
        augmented_data.append(noised)
    return np.array(augmented_data)

# Load and preprocess the dataset
def load_data(dataset_path):
    X, y = [], []
    for dirpath, _, filenames in os.walk(dataset_path):
        for file_name in filenames:
            if file_name.endswith('.wav'):
                file_path = os.path.join(dirpath, file_name)
                label = dirpath.split("/")[-1]
                features = extract_features(file_path)
                X.append(features)
                y.append(label)
    X = np.array(X)
    X = X[..., np.newaxis]  # Add channel dimension for Conv2D
    return X, np.array(y)

# Load Dataset
dataset_path = 'path/to/your/audio/dataset'
X, y = load_data(dataset_path)

# Encode labels
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)
y_categorical = to_categorical(y_encoded, num_classes=NUM_CLASSES)

# Train/Test split
X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42)

# Model Architecture
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(N_MFCC, X.shape[2], 1)),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(NUM_CLASSES, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Callbacks
callbacks = [
    EarlyStopping(patience=5, restore_best_weights=True),
    ModelCheckpoint('best_model.h5', save_best_only=True)
]

# Model Training
model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test), callbacks=callbacks)

# Evaluate the model
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true_classes = np.argmax(y_test, axis=1)

print("Accuracy:", accuracy_score(y_true_classes, y_pred_classes))
print("Precision:", precision_score(y_true_classes, y_pred_classes, average='weighted'))
print("Recall:", recall_score(y_true_classes, y_pred_classes, average='weighted'))
print("F1-score:", f1_score(y_true_classes, y_pred_classes, average='weighted'))
print(classification_report(y_true_classes, y_pred_classes, target_names=label_encoder.classes_))

# Save Model
model.save('audio_classification_model.h5')
